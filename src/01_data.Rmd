# Data Preparation

```{r, include=FALSE, eval=FALSE}
# George - Chad and I put our heads together about finishing the data processing and how we want to present things. Below are a few notes, but I think Chad is going to edit these and then you should edit/add based on your experience actually getting this done:
# 
# * Markdown site
#   ** can you remove the hyperlink to the cloud2trees site
#   ** can you add everyone's names you, me, chad, and sophie
#   ** Can you add a section 1.3 Processing Workflow and then add the attached workflow graphic
#   ** Sophie is going to take the tree data once it is clipped to the 30 m buffer and run it through the TREES program to get it formatted and assign surface fuels. It it all works out, Sophie is creating R code to create interactive 3D plots of the .dat files, which would be cool to integrate as like a section 3.1.4 QUIC-Fire Ready Data.
# ----Tell me and sophie when you have the clipped down data ready, I am adding her to the OneDrive
#   ** Then add section 8 Lessons Learned
# ----8.1 Data Processing Challenges/Gaps
# * LANDFIRE canopy biomass estimation errors, this could lead to underestimating tree level crown bulk density
#   ** LANDFIRE estimated bulk density values seem low for three of the sites
# * FIA Forest Type mapping errors
# * Intrinsic fuel properties currently user defined (e.g., fuel moisture, low heat of combustion, surface area to volume, etc.)
# * Requires ocular interpretation to tune trees extraction process, future work could automate starting parameters by forest type
# * Data formatting for fire modeling currently only done by TREES program
# * Surface fuels are currently assigned as either constants or as spatially formatted using the TREES program
# * Most metrics require broader validation across forest types than has been completed
# * Future linkages are possible to model tree parameters from NAIP/Satellite derived canopy height models
# ----8.2 Challenges with these Demos:
# * Data from USGS and Forest Service Data Archive were directly usable while other data sources lacked projection information and documented metadata
#   ** Only about half of the data was available in public access portals
#   ** About a third of the data delivered with missing metadata that initially prevented processing
# * Data interpretation/comparison is hindered by having 3-12 year gap between datasets at a site
# 
# Thank you all for hoping on this, I think it will lead to some good opportunities,


```

Let's check out the data we need to process and create: 1) a processing data frame; 2) a LAS catalog (`lidR` package) with information on the point cloud data

The priority list for processing this data is: 

* Sycan ALS
* Fort Stewart ALS
* New Jersey ALS
* Salt Cabin SfM
* Fort Stewart UAS Lidar
* Sycan UAS Lidar
* Salt Cabin ALS

I debated creating an automated pipeline to process all of the data but instead will create individual sections for each of the study sites and process them manually. This will overcome the challenge of defining unique variable window functions for use in ITD which we'll tune using `cloud2trees::itd_tuning()`

Load the standard libraries we use to do work

```{r, warning=FALSE, message=FALSE}
# bread-and-butter
library(tidyverse) # the tidyverse
library(viridis) # viridis colors
library(harrypotter) # hp colors
library(RColorBrewer) # brewer colors
library(scales) # work with number and plot scales
library(latex2exp)

# visualization
library(mapview) # interactive html maps
library(kableExtra) # tables
library(patchwork) # combine plots
library(ggmap) # correlation plots

# spatial analysis
library(terra) # raster
library(sf) # simple features
library(lidR) # lidar data
library(rgl) # 3d plots
library(cloud2trees) # the cloud2trees
```

```{r pkg-ld, include=F, warning=F, message=F}
# knit options
knitr::opts_chunk$set(
  echo = TRUE
  , warning = FALSE
  , message = FALSE
  # , results = 'hide'
  , fig.width = 10.5
  , fig.height = 7
)
# option to put satellite imagery as base layer of mapview maps
  mapview::mapviewOptions(
    homebutton = FALSE
    # , basemaps = c("Esri.WorldImagery","OpenStreetMap")
    , basemaps = c("OpenStreetMap", "Esri.WorldImagery")
  )
# clean session
remove(list = ls())
gc()
```

```{r, include=FALSE, eval=FALSE}
# i used this to keep only las tile files that overlapped with the aoi
# for Fort Stewart data I got from Ben Bright at: https://app.box.com/folder/330006690980
# in the folder "ft_stewart/als/Ft_Stewart_ALS_2025/LAZ"
library(tidyverse)
library(lidR)
setwd("c:/data/usfs/dod_cloud2trees_demo/src")
las_ctg <- lidR::readLAScatalog("../data/FortStewart/Ft_Stewart_ALS_2025/LAZ/")
las_ctg@data %>% dplyr::glimpse()
las_ctg@data %>% sf::st_crs()
aoi <- sf::st_read("c:/data/usfs/dod_cloud2trees_demo/data/FortStewart/Burn Unit F6_6.shp") %>% 
  sf::st_transform(sf::st_crs(las_ctg@data))
mapview::mapview(las_ctg@data) + mapview::mapview(aoi)
keep <- las_ctg@data %>% 
  sf::st_intersection(aoi %>% sf::st_buffer(50)) %>% 
  dplyr::pull(filename)
keep
las_ctg@data %>% 
  dplyr::filter(
    !filename %in% keep
  ) %>% 
  dplyr::pull(filename) %>% 
  purrr::map(unlink)
las_ctg <- lidR::readLAScatalog("../data/FortStewart/Ft_Stewart_ALS_2025/LAZ/")
mapview::mapview(las_ctg@data) + mapview::mapview(aoi)

# i used this to keep only las tile files that overlapped with the aoi
# for new jersey data I got from xxxx
# in the folder "newjersey/New_Jersey_UAS_LiDAR_2024/pointcloud"
library(tidyverse)
library(lidR)
setwd("c:/data/usfs/dod_cloud2trees_demo/src")
las_ctg <- lidR::readLAScatalog("../data/newjersey/New_Jersey_UAS_LiDAR_2024/")
las_ctg
las_ctg@data %>% dplyr::glimpse()
las_ctg@data %>% sf::st_crs()
aoi <- sf::st_read("c:/data/usfs/dod_cloud2trees_demo/data/newjersey/CB_BurnBlock.shp") %>% 
  sf::st_transform(sf::st_crs(las_ctg@data))
mapview::mapview(las_ctg@data) + mapview::mapview(aoi)
```

## Study Sites

let's check out the vector data of the study sites

```{r}
dir_temp <- "../data"
# what vector data?
df_temp <-
  list.files(dir_temp, pattern = ".*\\.(shp|gpkg)$", recursive = T) %>% 
  dplyr::tibble() %>% 
  setNames("fpath") %>% 
  dplyr::filter(
    !str_detect(fpath, "point_cloud_processing")
  ) %>% 
  dplyr::mutate(
    study_site = dirname(fpath)
    , fpath = file.path(dir_temp, fpath)
    , fdir = dirname(fpath)
  ) %>% 
  dplyr::group_by(study_site) %>% 
  dplyr::filter(dplyr::row_number()==1) %>% 
  dplyr::ungroup()
if(nrow(df_temp)==0){stop("no vector data found")}
# load in the vector data
study_sites_sf <- 1:nrow(df_temp) %>% 
  purrr::map(\(x)
    sf::st_read(
      dsn = df_temp$fpath[x]
    ) %>%
    # put all in the same projection
    sf::st_transform(crs=5070) %>% 
    dplyr::mutate(study_site = df_temp$study_site[x]) %>% 
    dplyr::select(study_site)
  ) %>% 
  dplyr::bind_rows() %>% 
  dplyr::inner_join(df_temp, by = "study_site")
# figure out where the point cloud data is
ptcld_df_temp <-
  1:nrow(study_sites_sf) %>% 
  purrr::map(function(x){
    # look for dirs with las/laz
      dirs <-
        study_sites_sf$fdir[x] %>% 
        list.files(pattern = ".*\\.(laz|las)$", recursive = T, full.names = T) %>% 
        dirname() %>%
        tolower() %>% 
        unique() %>% 
        purrr::keep(
          ~ !stringr::str_detect(.x, "point_cloud_processing")
        )
    # gen df
    df <- dplyr::tibble(
        als_dir = character(1)
        , uas_lidar_dir = character(1)
        , uas_sfm_dir = character(1)
      ) %>% 
      dplyr::mutate(
       als_dir = purrr::keep(dirs, ~ stringr::str_detect(.x, "als"))[1] %>% dplyr::coalesce(as.character(NA))
        , uas_lidar_dir = purrr::keep(dirs, ~ stringr::str_detect(.x, "uas") & stringr::str_detect(.x, "lidar"))[1] %>% dplyr::coalesce(as.character(NA))
        , uas_sfm_dir = purrr::keep(dirs, ~ stringr::str_detect(.x, "uas") & stringr::str_detect(.x, "sfm"))[1] %>% dplyr::coalesce(as.character(NA))
        , fdir = study_sites_sf$fdir[x]
      )
    return(df)
  }) %>% 
  dplyr::bind_rows()
# add ptcld dirs to data
study_sites_sf <- study_sites_sf %>% 
  dplyr::left_join(ptcld_df_temp, by = "fdir")
# what?
study_sites_sf %>% 
  dplyr::glimpse()
```

where are these places?

```{r}
# first plot a point so we can see it on the map
mapview::mapview(
  sf::st_centroid(study_sites_sf)
  , zcol = "study_site"
  , cex = 5
  , label = T
  , legend = T
  , popup = T
  , layer.name = "study areas"
) + 
# add the study bounds
mapview::mapview(
  study_sites_sf
  , color = "black"
  , lwd = 2
  , alpha.regions = 0
  , label = F
  , legend = F
  , popup = F
)
```

let's create a pretty name for each site

```{r}
study_sites_sf <- study_sites_sf %>% 
  dplyr::mutate(
    study_site_lab = dplyr::case_match(
      tolower(study_site)
      , "fortstewart" ~ "Fort Stewart (GA)"
      , "newjersey" ~ "Cedar Bridge (NJ)"
      , "saltcabin" ~ "Salt Cabin (CO)"
      , "sycanmarsh" ~ "Sycan Marsh (OR)"
    ) %>% 
    dplyr::coalesce(study_site)
  )
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Point Cloud Data

Let's check out the point cloud data we got

```{r}
las_df_temp <-
  study_sites_sf %>% 
  sf::st_drop_geometry() %>% 
  dplyr::select(study_site, tidyselect::ends_with("_dir")) %>% 
  tidyr::pivot_longer(
    cols = -c(study_site)
    , values_drop_na = T
  ) %>% 
  dplyr::mutate(
    name = stringr::str_remove_all(name, "_dir")
    # !!!!!! the folders must be named with this pattern for date extraction to work !!!!!!!!!!!!!!!
    # !!!!!! could manually make a lookup table.... but ohwell !!!!!!!!!!!!!!!
    , als_nm = value %>% 
      stringr::str_extract("(uas_lidar|uas_sfm|als)_(\\d{4})")
    , nm = stringr::str_c(
      study_site
      , dplyr::coalesce(als_nm, name)
      , sep = "_"
    )
  )
# directory with the downloaded .las|.laz files
study_sites_las_ctg <- 1:nrow(las_df_temp) %>% 
  purrr::map(\(x)
    lidR::readLAScatalog(las_df_temp$value[x])
  )
names(study_sites_las_ctg) <- las_df_temp$nm
# what are these ctgs?
study_sites_las_ctg
```

plot the point cloud catalog with the stand boundary

```{r}
ggplot2::ggplot() + 
  ggplot2::geom_sf(
    data = study_sites_sf %>% dplyr::slice(1)
    , color = "navy", fill = NA
  ) + 
  ggplot2::geom_sf(
    data = study_sites_las_ctg[[1]]$geometry %>% sf::st_transform(sf::st_crs(study_sites_sf))
    , color = "gray33", fill = NA
  ) + 
  ggplot2::theme_light()
# lidR::st_crs(ctg_temp[[3]])

```

let's make a quick function to grab a background map (e.g. like a Google Map) for an AOI using the `ggmap` package

```{r, warning=F, message=FALSE, results=F}
library(ggmap)
library(ggspatial)
#########################################################################
#########################################################################
# Make each plot individually by landscape as solution to small multiples
# this block defines function
#########################################################################
##################hack to align plots for ggmap
ggmap_bbox_fn <- function(map, my_crs=3857) {
    if (!inherits(map, "ggmap")) stop("map must be a ggmap object")
    # Extract the bounding box (in lat/lon) from the ggmap to a numeric vector, 
    # and set the names to what sf::st_bbox expects:
    map_bbox <- setNames(unlist(attr(map, "bb")), c("ymin", "xmin", "ymax", "xmax"))
    # Convert the bbox to an sf polygon, transform it to 3857, 
    # and convert back to a bbox (convoluted, but it works)
    bbox_3857 <- st_bbox(st_transform(st_as_sfc(st_bbox(map_bbox, crs = 4326)), my_crs))
    # Overwrite the bbox of the ggmap object with the transformed coordinates 
    attr(map, "bb")$ll.lat <- bbox_3857["ymin"]
    attr(map, "bb")$ll.lon <- bbox_3857["xmin"]
    attr(map, "bb")$ur.lat <- bbox_3857["ymax"]
    attr(map, "bb")$ur.lon <- bbox_3857["xmax"]
    map
}
plt_crs <- 3857
#########################################################################
#########################################################################
# for google maps... have to:
# 1) get api key at https://console.cloud.google.com/apis/dashboard
# 2) run ggmap::register_google(key = "mykey_xxxxxxxxx", write = T)
#########################################################################
my_ggmap_basemap <- function(
  sf_data
  , zoom_level = 14 # from 3 (continent) to 21 (building), default value 10 (city)
  , buffer_box = 2600
  , my_crs = plt_crs
  , scale_location = "bl"
  , my_maptype = "stamen_terrain"
  ## stamen
  # stamen_terrain, stamen_toner, stamen_toner_lite, stamen_watercolor, stamen_terrain_background
  # , stamen_toner_background, stamen_terrain_lines, stamen_terrain_labels
  # , stamen_toner_lines, stamen_toner_labels
  ## googlmap
  # "terrain", "satellite", "roadmap", and "hybrid"
  , add_sf_data = F
  , outline_sf_data_col = "white"
  , outline_lwd = 0.7
) {
  
  # # should zoom in?
  # zoom_level <- 14 # 11
  # # should buffer extend?
  # buffer_box <- 2600 # 20000
  # bounding box
  bb_temp <-
    sf_data %>% 
    sf::st_bbox() %>% 
    sf::st_as_sfc() %>% 
    sf::st_transform(crs=5070) %>% 
    sf::st_buffer(as.numeric(buffer_box)) %>% 
    sf::st_transform(crs=4326)
  
  center_temp <- sf::st_centroid(bb_temp) %>% sf::st_coordinates() %>% .[1,]
  # set bbox for get call
  bb_temp <- sf::st_bbox(bb_temp)
  bbox_temp <- c(
    bottom = bb_temp[[2]]
    , top = bb_temp[[4]]
    , right = bb_temp[[3]]
    , left = bb_temp[[1]]
  )
  
  # ggmap::get_stadiamap vs ggmap::get_googlemap
  if(
    tolower(my_maptype) %in% c("terrain", "satellite", "roadmap", "hybrid")
  ){
    is_google <- T
    
    hey_ggmap <- ggmap::get_googlemap(
      center = center_temp
      , zoom = zoom_level
      , maptype = tolower(my_maptype)
      , crop = T
    )
  }else{
    is_google <- F
    
    hey_ggmap <- ggmap::get_stadiamap(
      bbox = bbox_temp
      , zoom = zoom_level
      , maptype = tolower(my_maptype) #"stamen_terrain" #"stamen_toner_lite"
      , crop = T
    )
  
    # ggmap::ggmap(hey_ggmap)
    # apply align function
    hey_ggmap <- ggmap_bbox_fn(hey_ggmap, my_crs) # Use the function
  }
  # plot
  plt_basemap <-
    ggmap::ggmap(hey_ggmap) + 
    ggplot2::coord_sf(
      expand = FALSE
    ) +
    ggplot2::theme_light() +
    ggplot2::theme(
      legend.position = "none"
      , plot.title = ggplot2::element_blank()
      , strip.text = ggplot2::element_blank()
      , axis.title = ggplot2::element_blank()
      , axis.text = ggplot2::element_blank()
      , axis.ticks = ggplot2::element_blank()
      , panel.grid = ggplot2::element_blank()
      , plot.margin = ggplot2::margin(0, 0, 0, 0, "cm")
    )
  
  ### add data?
  if(scale_location %in% c("bl", "br", "tr", "tl")){
    plt_basemap <- plt_basemap + 
      ggspatial::annotation_scale(
        location = scale_location
        , style = "ticks"
        , pad_x = unit(0.1, "cm")
        , pad_y = unit(0.1, "cm")
      )
  }
  
  if(add_sf_data){
    if(is_google){
      plt_basemap <- 
        plt_basemap +
        ggplot2::geom_sf(
          data = sf_data %>% 
            sf::st_transform(4326)
          , fill = NA, color = outline_sf_data_col, lwd = outline_lwd
          , inherit.aes = F
        )
        # ggplot2::geom_path(
        #   data = sf_data %>% 
        #     sf::st_transform(4326) %>% 
        #     st_coordinates() %>% 
        #     as.data.frame() %>% 
        #     dplyr::mutate(lon = X, lat = Y) %>% 
        #     sf::st_as_sf(coords = c("X","Y"), crs = 4326)
        #   , fill = NA, color = outline_sf_data_col
        #   , inherit.aes = F
        # )
    }else{
      plt_basemap <- 
        plt_basemap +
        ggplot2::geom_sf(
          data = sf_data %>%
            sf::st_transform(crs=plt_crs)
          , fill = NA, color = outline_sf_data_col, lwd = outline_lwd
          , inherit.aes = F
        )
    }
  }
  
  return(plt_basemap)
}

```

```{r, include=FALSE, eval=FALSE}
my_ggmap_basemap(
  sf_data = study_sites_sf %>% dplyr::filter(study_site == "SaltCabin")
  , zoom_level = 16
  , buffer_box = 100
  , my_maptype = "satellite"
  , add_sf_data = T
  , outline_sf_data_col = "salmon"
  , outline_lwd = 2
)
```

make a function specific to this data and task to grab the basemap with `my_ggmap_basemap()` and overlay the point cloud data and the study area bounds

```{r, eval = T}
plt_fn_temp <- function(
  record_study_sites_las_ctg
  , my_study_sites_las_ctg = study_sites_las_ctg
  , my_study_sites_sf = study_sites_sf
  # , zoom_level = 14, buffer_box = 2600, my_crs = plt_crs, scale_location = "bl", my_maptype = "stamen_terrain"
) {
  
  # make a function to grab the basemap with my_ggmap_basemap, and overlay the point cloud data and the study area bounds
  plt_basemap_temp <- my_ggmap_basemap(
    sf_data = my_study_sites_las_ctg[[record_study_sites_las_ctg]]$geometry
    , zoom_level = 14
    , buffer_box = 3333
    , my_crs = plt_crs
    , scale_location = "bl"
    , my_maptype = "stamen_terrain"
  )
  
  # plot
  plt2_temp <-
    plt_basemap_temp + 
      ggplot2::geom_sf(
        data = 
          my_study_sites_las_ctg[[record_study_sites_las_ctg]]$geometry %>%
          sf::st_transform(crs=plt_crs)
        , fill = NA, lwd = 0.7, color = "gray8"
        , inherit.aes = F
      ) +
      ggplot2::geom_sf(
        data = my_study_sites_sf %>% 
          dplyr::filter(
            study_site %in% (my_study_sites_las_ctg[record_study_sites_las_ctg] %>% 
              names() %>% 
              stringr::word(sep = "_"))
          ) %>% 
          sf::st_transform(crs=plt_crs)
        , fill = NA, color = "navy", lwd = 1.4
        , inherit.aes = F
      ) +
      ggplot2::labs(
        subtitle = paste0(
          my_study_sites_sf %>% 
          dplyr::filter(
            study_site %in% (my_study_sites_las_ctg[record_study_sites_las_ctg] %>% 
              names() %>% 
              stringr::word(sep = "_"))
          ) %>% 
          dplyr::pull(study_site_lab)
          , " - "
          , (my_study_sites_las_ctg[record_study_sites_las_ctg] %>% 
              names() %>% 
              stringr::str_replace_all("_"," ") %>% 
              stringr::str_replace("^\\S+\\s*", "") %>% 
              toupper()
            )
          , " data"
        )
      )
    
  return( plt2_temp )
}
# for each las ctg with crs
sf::st_crs(study_sites_las_ctg$NewJersey_als_2012) <- paste0("EPSG:", 32618) #  D;
plts_temp <- 
  1:length(study_sites_las_ctg %>% purrr::discard(names(.) %in% c("FortStewart_uas_lidar","NewJersey_als"))) %>% 
  purrr::map(
    \(x)
    plt_fn_temp(
      record_study_sites_las_ctg = x
      , my_study_sites_las_ctg = study_sites_las_ctg %>% purrr::discard(names(.) %in% c("FortStewart_uas_lidar","NewJersey_als"))
      , 
    )
  )
# patchwork it
patchwork::wrap_plots(plts_temp, ncol = 2)
# 
```

```{r, include=FALSE, eval=T}
ggplot2::ggsave(
  "../data/ptcld_aoi_extents.jpg"
  , dpi = "print"
  , height = 11, width = 8
)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

```{r, include = F, eval = F}
# can we add an inset map?
# get big map
plt_basemap_inset <-
  my_ggmap_basemap(
    sf_data = las_ctg_sf$geom %>%
      dplyr::as_tibble() %>% 
      dplyr::mutate(rn = dplyr::row_number()) %>% 
      sf::st_as_sf(sf_column_name = "geometry") %>% 
      dplyr::filter(rn==max(rn))
    , zoom_level = 6
    , buffer_box = 565000
    , my_maptype = "stamen_toner_lite"
    , scale_location = NA
  ) 
# plt_basemap_inset
# add point
plt_inset <- plt_basemap_inset + 
  ggplot2::geom_sf(
        data = stand_sf %>% 
          dplyr::filter(unit_id==2) %>% 
          sf::st_geometry() %>%
          sf::st_centroid() %>% 
          `+`(c(0,12000)) %>% # moves the point up so not blocking text label
          sf::st_set_crs(sf::st_crs(stand_sf)) %>% 
          sf::st_transform(crs=plt_crs)
        , fill = NA, color = my_pal[2]
        , size = 1.8, shape = 18
        , inherit.aes = F
      )
# combine
plt2_temp + 
  patchwork::inset_element(
    plt_inset
    , left = 0.733, bottom = 0.753
    , right = 1, top = 1
    , align_to = "full"
  )
```

```{r, include = F, eval=FALSE}
# get sentinel2 basemap
# Load necessary libraries (ensure they are installed)
# These are loaded here for clarity, but in a package, they would be listed in DESCRIPTION Imports.
# In a regular script, 'library()' calls are sufficient.
library(sf)
library(rsi) #get sentinel-2 imagery
library(ggplot2)
library(terra)
library(dplyr)

#' Plot Sentinel-2 Imagery as a background with AOI overlay
#'
#' This function downloads Sentinel-2 imagery for a specified area of interest,
#' plots it as a background using ggplot2, and overlays the AOI polygon.
#'
#' @param aoi An `sf` polygon object defining the area of interest.
#'            Must have a valid CRS.
#' @param start_date A character string in "YYYY-MM-DD" format specifying the
#'                   start date for imagery search.
#' @param end_date A character string in "YYYY-MM-DD" format specifying the
#'                 end date for imagery search.
#' @param output_filename A character string specifying the path and filename
#'                        (including .tif extension) to save the downloaded
#'                        composite image. Defaults to a temporary file.
#' @param bands A character vector specifying the Sentinel-2 bands to download
#'              for the true-color composite (default: c("B04", "B03", "B02") for RGB).
#' @param composite_function A character string specifying the function to use
#'                           for creating the composite image from multiple
#'                           scenes (e.g., "median", "mean", "max", "min").
#'                           Defaults to "median".
#' @param aoi_border_color A character string specifying the color of the AOI
#'                         polygon border (default: "red").
#' @param aoi_border_linewidth A numeric value specifying the width of the AOI
#'                             polygon border (default: 1).
#' @param plot_title A character string for the ggplot title (default: "Sentinel-2 Imagery with AOI").
#'
#' @return A `ggplot` object containing the Sentinel-2 imagery and AOI overlay.
#' @export
#'
#' @examples
#' \dontrun{
#' # Example: Creating a simple rectangular AOI in WGS84
#' aoi_example <- sf::st_bbox(c(xmin = -105.15, ymin = 40.55, xmax = -105.05, ymax = 40.65), 
#'                        crs = 4326) %>% sf::st_as_sfc()
#' 
#' # Plot the imagery
#' my_plot <- plot_sentinel2_aoi(aoi = aoi_example,
#'                              start_date = "2024-06-01",
#'                              end_date = "2024-06-30",
#'                              aoi_border_color = "blue",
#'                              plot_title = "My Custom Sentinel-2 Plot")
#' print(my_plot)
#' }
plot_sentinel2_aoi <- function(
  sf_data
  , buffer_box = 20
  # revisit frequency of ~5 days
  , start_date # "2024-06-01"
  , end_date # "2024-06-30"
  , output_filename = tempfile(fileext = ".tif")
  , bands = c("red", "blue", "green")
    # c("B04", "B03", "B02") # Red, Green, Blue bands
  , composite_function = "median"
  , aoi_border_color = "red"
  , aoi_border_linewidth = 1
  , plot_title = "Sentinel-2 Imagery with AOI"
  , stac_source = "https://planetarycomputer.microsoft.com/api/stac/v1/"
){

  # Ensure AOI is a valid sf object
  if (!inherits(sf_data, "sf")) {
    stop("Input sf_data must be an sf polygon object.")
  }
  # # should zoom in?
  # zoom_level <- 14 # 11
  # # should buffer extend?
  # buffer_box <- 2600 # 20000
  # bounding box
  aoi <-
    sf_data %>% 
    sf::st_bbox() %>% 
    sf::st_as_sfc() %>% 
    sf::st_transform(crs=5070) %>% 
    sf::st_buffer(as.numeric(buffer_box)) %>% 
    sf::st_transform(crs=4326) %>% # same as get_map return
    sf::st_as_sf()

  # --- 1. Download Sentinel-2 Imagery using rsi::get_stac_data ---
  message(paste0("Downloading Sentinel-2 imagery composite (", composite_function, ") for ", start_date, " to ", end_date, "..."))
  
  s2_images_path <- rsi::get_stac_data(
    aoi = aoi,
    start_date = start_date,
    end_date = end_date,
    asset_names = bands, # Use asset_names for the bands
    stac_source = stac_source,
    collection = "sentinel-s2-l2a-cogs", # Sentinel-2 Level 2A, Cloud Optimized GeoTiffs
    composite_function = composite_function,
    output_filename = output_filename
    # Add other parameters like mask_band, mask_function, etc. if needed for advanced use
  )

  if (is.null(s2_images_path) || !file.exists(s2_images_path)) {
    stop("Failed to download Sentinel-2 imagery. Check AOI, date range, and STAC source.")
  }

  # Load the downloaded image as a terra SpatRaster object
  s2_raster <- terra::rast(s2_images_path)

  # --- 2. Prepare Imagery for Plotting with ggplot2 ---
  message("Preparing imagery for plotting...")
  s2_df <- as.data.frame(s2_raster, xy = TRUE)

  # Rename the band columns for easier use (assuming RGB order)
  # Adjust if a different band order is used in the 'bands' argument
  if (length(bands) == 3) {
      names(s2_df) <- c("x", "y", "red", "green", "blue")
  } else {
      # Handle cases with different number of bands or non-RGB plots
      # For now, just use generic names if not 3 bands for true color
      names(s2_df)[3:(2 + length(bands))] <- bands
      # If not RGB, direct 'rgb()' might not be appropriate.
      # This part might need further customization based on the bands.
      warning("Plotting only the first three bands as RGB. Adjust 'bands' for different visualization or 's2_df$rgb' calculation.")
      s2_df$rgb <- with(s2_df, rgb(s2_df[,3] / max(s2_df[,3], na.rm = TRUE),
                                              s2_df[,4] / max(s2_df[,4], na.rm = TRUE),
                                              s2_df[,5] / max(s2_df[,5], na.rm = TRUE)))
  }


  # Normalize and convert to RGB for plotting true color
  # Handle potential NA values in imagery data gracefully
  max_red <- max(s2_df$red, na.rm = TRUE)
  max_green <- max(s2_df$green, na.rm = TRUE)
  max_blue <- max(s2_df$blue, na.rm = TRUE)

  s2_df$rgb <- with(s2_df, rgb(red / max_red, green / max_green, blue / max_blue))

  # --- 3. Plot the Imagery and Overlay the AOI Polygon ---
  message("Generating plot...")
  ggplot_obj <- ggplot2::ggplot() +
    # Plot the Sentinel-2 imagery as a background
    ggplot2::geom_raster(data = s2_df, ggplot2::aes(x = x, y = y, fill = rgb)) +
    ggplot2::scale_fill_identity() + # Use the pre-calculated RGB colors
    
    # Overlay the Area of Interest polygon
    ggplot2::geom_sf(data = aoi, fill = NA, color = aoi_border_color, linewidth = aoi_border_linewidth) + 
    
    # Add titles and labels
    ggplot2::labs(title = plot_title,
         x = "Longitude",
         y = "Latitude") +
    ggplot2::theme_minimal() + # Use a clean theme
    ggplot2::coord_sf() # Ensures correct spatial projection

  return(ggplot_obj)

}


xxx <- plot_sentinel2_aoi(
  sf_data = study_sites_sf %>% dplyr::filter(study_site == "SaltCabin")
  , buffer_box = 50
  , start_date = "2025-06-01"
  , end_date = "2025-06-30"
  , output_filename = "../data/sentineltesttest.tif"
)

# Generate the plot
aoi_temp <- sf::st_bbox(c(xmin = -105.15, ymin = 40.55, xmax = -105.05, ymax = 40.65), crs = 4326) %>% 
  sf::st_as_sfc()
f_temp <- tempfile(fileext = ".tif")

aoi_temp <- sf::st_point(c(-74.912131, 44.080410))
aoi_temp <- sf::st_set_crs(sf::st_sfc(aoi_temp), 4326)
aoi_temp <- sf::st_buffer(sf::st_transform(aoi_temp, 5070), 100)


s2_images_path <- rsi::get_stac_data(
    aoi = aoi_temp,
    start_date = "2022-06-01",
    end_date = "2022-06-30",
    asset_names = c(
    "red", "blue", "green"
  ), # Use asset_names for the bands
    stac_source = "https://planetarycomputer.microsoft.com/api/stac/v1/",
    collection = "sentinel-s2-l2a-cogs", # Sentinel-2 Level 2A, Cloud Optimized GeoTiffs
    composite_function = "median",
    output_filename = f_temp
    # Add other parameters like mask_band, mask_function, etc. if needed for advanced use
  )
# !!!! there is no data for anywhere...looks like microsoft planetarycomputer is discontinued???
```

## ITD window functions

```{r}
# set up initial list with default functions
my_ws_functions <- cloud2trees::itd_ws_functions()
# add to list
my_ws_functions$log_les_ccv_fn <- function (x) {
    y <- dplyr::case_when(
      is.na(x) ~ 0.001
      , x < 0 ~ 0.001
      , x > exp(5)-1 ~ 5
      , TRUE ~ log(x+1)
    )
    return(y)
}
# add to list
my_ws_functions$log_mor_ccv_fn <- function (x) {
    y <- dplyr::case_when(
      is.na(x) ~ 0.001
      , x < 0 ~ 0.001
      , x > exp(7/1.5)-1 ~ 7
      , TRUE ~ 1.5*log(x+1)
    )
    return(y)
}
# add to list
my_ws_functions$lin_lo_slp_fn <- function (x) {
    y <- dplyr::case_when(
      is.na(x) ~ 0.001
      , x < 0 ~ 0.001
      , x > (4-0.75)/0.04 ~ 4
      , TRUE ~ 0.75 + (x * 0.04)
    )
    return(y)
}
```

run each function over a range of heights to see what they return on a plot

```{r}
# get ws by ht for each fn
ws_fn_df <- 1:length(my_ws_functions) %>%
  purrr::map(function(x){
    nm <- my_ws_functions[x] %>% names() %>% as.character()
    fn <- my_ws_functions[[x]]
    # est
    height <- seq(from=0,to=60,by=0.5)
    ws <- fn(height) %>% unlist()
    df <- dplyr::tibble(
        height = height
        , ws = ws
      ) %>% 
      dplyr::mutate(ws_fn_nm = nm) %>% 
      dplyr::relocate(ws_fn_nm)
    return(df)
  }) %>% 
  dplyr::bind_rows()
# huh?
ws_fn_df %>% dplyr::glimpse()
```

plot of all ITD variable window functions for testing

```{r}
ws_fn_df %>% 
  ggplot2::ggplot(mapping = ggplot2::aes(x = height, y = ws, color = ws_fn_nm)) +
  ggplot2::geom_line(lwd=1) +
  # ggplot2::scale_color_manual(values = pal_ws) +
  # ggplot2::scale_color_viridis_d(option = "turbo") +
  ggplot2::scale_color_brewer(palette = "Dark2") +
  ggplot2::xlim(-3,NA) +
  ggplot2::ylim(-0.1,NA) +
  ggplot2::labs(
    x = "heights", y = "ws"
    , color = "variable\nwindow\nfunction"
    , subtitle = "ITD variable window functions for testing"
  ) +
  ggplot2::theme_light() +
  ggplot2::guides(
    color = ggplot2::guide_legend(override.aes = list(lwd = 6))
  )
```

## Other plotting functions

function to plot raster with vector data overlaid

```{r}
plt_rast_poly_fn <- function(
  rast
  , poly
  , crop = T
  , mask = F
  , buff = 22
  , col = "red"
  , lwd = 1
  , title = ""
  , leg_pos = "top"
) {
  if(crop){
    rast <- rast %>% 
      terra::crop(
        poly %>% 
          sf::st_buffer(buff) %>% 
          sf::st_transform(terra::crs(rast)) %>% 
          terra::vect()
      )
  }
  if(mask){
    rast <- rast %>% 
      terra::mask(
        poly %>% 
          sf::st_buffer(buff) %>% 
          sf::st_transform(terra::crs(rast)) %>% 
          terra::vect()
      )
  }
  
  # Convert SpatRaster to a data frame for ggplot
  rast_df <- terra::as.data.frame(rast, xy=TRUE) %>% rename(f=3)

  # Create the base raster plot
  p <- ggplot2::ggplot() +
    ggplot2::geom_raster(
      data = rast_df, aes(x = x, y = y, fill = f)
    ) +
    # ggplot2::scale_fill_viridis_c() + # Use a colorblind-friendly palette
    # ggplot2::coord_sf(crs = terra::crs(rast)) +  # Match the CRS
    ggplot2::labs(fill = "") +
    ggplot2::theme_void() +
    ggplot2::theme(
      legend.position = leg_pos
      , legend.text = ggplot2::element_text(angle = 90, vjust = 0.5, size = 7)
      , plot.subtitle = ggplot2::element_text(hjust = 0.5)
      # , plot.title = ggplot2::element_text(hjust = 0.5)
    )

  # Add the polygon overlay
  p <- p +
    ggplot2::geom_sf(
      data = poly %>% sf::st_transform(terra::crs(rast))
      , fill = NA, color = col, lwd = lwd
    ) +
    ggplot2::labs(subtitle = title)

  return(p)
}
#####
plt_crown_attr_fn <- function(
  crowns
  , aoi
  , col = "navy"
  , lwd = 1
  , title = ""
  , leg_pos = "top"
  # polygon attrs
  , fill_var
  , palette = "Blues" # see ggplot2::scale_fill_distiller
) {
ggplot2::ggplot(
    data = aoi %>% sf::st_transform(sf::st_crs(crowns))
  ) + 
  ggplot2::geom_sf(fill = NA, color = col, lwd = lwd) +
  ggplot2::geom_sf(
    data = crowns %>% 
      sf::st_intersection(
        aoi %>% sf::st_transform(sf::st_crs(crowns))
      )
    , mapping = ggplot2::aes(fill = .data[[fill_var]])
    , color = NA
  ) + 
  ggplot2::scale_fill_distiller(palette = palette, name = title, direction = 1, labels = scales::comma_format(accuracy = 1)) +
  ggplot2::theme_void() +
  ggplot2::theme(
    legend.position = leg_pos
    , legend.direction = "horizontal"
    , legend.title = ggplot2::element_text(size = 7)
    , legend.text = ggplot2::element_text(size = 6)
  )
}
# load our FIA forest type group raster for use later
# load lookup
  foresttype_lookup <- file.path(cloud2trees::find_ext_data()[["foresttype_dir"]], "foresttype_lookup.csv") %>% 
    readr::read_csv(progress = F, show_col_types = F) %>% 
    dplyr::distinct(forest_type_group_code, forest_type_group, hardwood_softwood) %>% 
    dplyr::mutate(forest_type_group = stringr::str_remove(forest_type_group, " group"))
  
# forest type group summary
foresttype_sum_fn <- function(crowns, aoi, unit) {
  crowns %>% 
    sf::st_intersection(
      aoi %>% sf::st_transform(sf::st_crs(crowns))
    ) %>% 
    sf::st_drop_geometry() %>% 
  dplyr::mutate(unit_name = unit) %>% 
    sf::st_drop_geometry() %>% 
    dplyr::count(unit_name, forest_type_group) %>% 
    dplyr::arrange(unit_name, desc(n)) %>% 
    dplyr::group_by(unit_name) %>% 
    dplyr::mutate(
      pct = scales::percent(n/sum(n), accuracy = 0.1) 
    ) %>% 
    dplyr::ungroup() %>% 
    dplyr::mutate(n = scales::comma(n,accuracy=1)) %>% 
    kableExtra::kbl(
      caption = "Count of trees by FIA Forest Type Group"
      , digits = 2
      , col.names = c(
        "."
        , ""
        , "# trees"
        , "% trees"
      )
    ) %>% 
    kableExtra::kable_styling() %>% 
    kableExtra::collapse_rows(columns = 1, valign = "top")
}

# summarize tree metrics
stats_sum_fn <- function(crowns, aoi, unit) {
  crowns %>% 
    sf::st_intersection(
      aoi %>% sf::st_transform(sf::st_crs(crowns))
    ) %>% 
    sf::st_drop_geometry() %>% 
  dplyr::mutate(unit_name = unit) %>% 
    dplyr::group_by( unit_name) %>%
    dplyr::summarise(
      dplyr::across(
        c(tree_height_m, dbh_cm, tree_cbh_m, max_crown_diam_height_m, cruz_tree_kg_per_m3, landfire_tree_kg_per_m3)
        , .fns = list(mean = mean, median = median, sd = sd, min = min, max = max)
      )
      , n = dplyr::n()
    ) %>% 
    dplyr::ungroup() %>% 
    tidyr::pivot_longer(cols = -c( unit_name,n)) %>% 
    dplyr::mutate(
      agg = stringr::word(name,-1,sep = "_")
      , metric = stringr::str_remove_all(name, paste0("_",agg))
    ) %>% 
    dplyr::select(-name) %>% 
    dplyr::mutate(
      value = dplyr::case_when(
        metric == "tree_height_m" ~ scales::comma(value,accuracy=0.1)
        , metric == "dbh_cm" ~ scales::comma(value,accuracy=0.1)
        , metric == "tree_cbh_m" ~ scales::comma(value,accuracy=0.1)
        , metric == "max_crown_diam_height_m" ~ scales::comma(value,accuracy=0.1)
        , metric == "cruz_tree_kg_per_m3" ~ scales::comma(value,accuracy=0.001)
        , metric == "landfire_tree_kg_per_m3" ~ scales::comma(value,accuracy=0.001)
        , T ~ scales::comma(value,accuracy=0.1)
      )
    ) %>% 
    tidyr::pivot_wider(names_from = agg, values_from = value) %>% 
    dplyr::mutate(
      unit_lab = paste0(
        unit_name
        ,"<br>("
        , scales::comma(n,accuracy=1)
        ," trees)"
      )
      , range = paste0(min, "â€”", max)
    ) %>% 
    dplyr::arrange( unit_name, desc(n)) %>% 
    dplyr::select(-c(unit_name,n,min,max)) %>% 
    dplyr::relocate(unit_lab) %>% 
    dplyr::mutate(
      metric = factor(
        metric
        , ordered = T
        , levels = c(
            "tree_height_m"
            , "dbh_cm"
            , "tree_cbh_m"
            , "max_crown_diam_height_m"
            , "cruz_tree_kg_per_m3"
            , "landfire_tree_kg_per_m3"
          )
        , labels = c(
            "Height (m)"
            , "DBH (cm)"
            , "Crown Base Ht. (m)"
            , "HMD (m)"
            , "Cruz CBD<br>kg m<sup>-3</sup>"
            , "LANDFIRE CBD<br>kg m<sup>-3</sup>"
          )
      )
    ) %>% 
    kableExtra::kbl(
      caption = "Summary statistics for selected metrics"
      , col.names = c(
        "Unit Name", "Metric"
        , "Mean", "Median"
        , "Std Dev", "Range"
      )
      , escape = F
      # , digits = 2
    ) %>% 
    kableExtra::kable_styling(font_size = 13) %>% 
    kableExtra::collapse_rows(columns = 1, valign = "top")
}
  
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
remove(ws_fn_df)
gc()
```
